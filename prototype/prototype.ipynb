{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93972f95",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\suena\\anaconda3\\lib\\site-packages (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\suena\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca8ea2c4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19045.2251]\n",
      "(c) Microsoft Corporation. All rights reserved.\n",
      "\n",
      "(base) C:\\Users\\suena\\PycharmProjects\\UCSDBootCamp\\capstone\\Survey>where python\n",
      "C:\\Users\\suena\\anaconda3\\python.exe\n",
      "C:\\Users\\suena\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n",
      "\n",
      "(base) C:\\Users\\suena\\PycharmProjects\\UCSDBootCamp\\capstone\\Survey>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5c221e5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19045.2251]\n",
      "(c) Microsoft Corporation. All rights reserved.\n",
      "\n",
      "(base) C:\\Users\\suena\\PycharmProjects\\UCSDBootCamp\\capstone\\Survey>pip install cmake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cmake\n",
      "  Downloading cmake-3.25.0-py2.py3-none-win_amd64.whl (32.6 MB)\n",
      "     --------------------------------------- 32.6/32.6 MB 13.1 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: cmake\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed cmake-3.25.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(base) C:\\Users\\suena\\PycharmProjects\\UCSDBootCamp\\capstone\\Survey>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32aa74f4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Using cached dlib-19.24.0.tar.gz (3.2 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): finished with status 'done'\n",
      "  Created wheel for dlib: filename=dlib-19.24.0-cp38-cp38-win_amd64.whl size=3053962 sha256=0632311e328a7f05fe56d83835f6f2568d2dec6e6b7eddf7bd54706df1fb8781\n",
      "  Stored in directory: c:\\users\\suena\\appdata\\local\\pip\\cache\\wheels\\4c\\d8\\2d\\a83b10e7bf10cd7d8bef36bf4dcd15b0c9ebf98f990bc984dd\n",
      "Successfully built dlib\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d410166",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\suena\\anaconda3\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\suena\\anaconda3\\lib\\site-packages (from face_recognition) (9.2.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\suena\\anaconda3\\lib\\site-packages (from face_recognition) (8.0.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\suena\\anaconda3\\lib\\site-packages (from face_recognition) (1.21.6)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\suena\\anaconda3\\lib\\site-packages (from face_recognition) (19.24.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\suena\\anaconda3\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.5)\n",
      "Installing collected packages: face_recognition\n",
      "Successfully installed face_recognition-1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\suena\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d9795a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Layer, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45fe3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f82af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e81d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # Load in the image\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    # Preprocessing steps - resizing the image to be 150x150\n",
    "    img = tf.image.resize(img, (150,150))\n",
    "    # Scale image to be between 0 and 1\n",
    "    img = img / 255.0\n",
    "    \n",
    "    # Return iimage\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb44c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "885b93cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Distance Layer\n",
    "# Create Siamese L1 distance class\n",
    "class L1Dist(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "    \n",
    "    # Similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287ad61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Reload model\n",
    "model = tf.keras.models.load_model('siamesemodel_VG16.h5', \n",
    "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f380b8a4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 661ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Create a HOG face detector using the built-in dlib class\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m face_detector \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mget_frontal_face_detector()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Run the HOG face detector on the image data.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# The result will be the bounding boxes of the faces in our image.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m detected_faces \u001b[38;5;241m=\u001b[39m face_detector(frame, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Capture the faces from webcam\n",
    "# Establish a connection to the webcam\n",
    "cam=0\n",
    "for i in range(4):\n",
    "    if cv2.VideoCapture(i):\n",
    "        cam=i\n",
    "        break\n",
    "    else:\n",
    "        print('no camera found')\n",
    "   \n",
    "cap = cv2.VideoCapture(cam)\n",
    "\n",
    "number_of_faces=0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Create a HOG face detector using the built-in dlib class\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    # Run the HOG face detector on the image data.\n",
    "    # The result will be the bounding boxes of the faces in our image.\n",
    "    detected_faces = face_detector(frame, 1)\n",
    "    number_of_faces = len(detected_faces)\n",
    "    \n",
    "    # Loop through each face found in the image\n",
    "    if number_of_faces == 2:\n",
    "        for i, face_rect in enumerate(detected_faces):\n",
    "\n",
    "            # Crop image and save\n",
    "            crop_image = frame[face_rect.top():face_rect.bottom(), face_rect.left():face_rect.right()]\n",
    "            cv2.imwrite(\"face{}.jpg\".format(i),crop_image)\n",
    "\n",
    "        # verify the faces\n",
    "        face_0 = tf.data.Dataset.list_files('face0.jpg').take(1)\n",
    "        face_1 = tf.data.Dataset.list_files('face1.jpg').take(1)\n",
    "        faces = tf.data.Dataset.zip((face_0, face_1, tf.data.Dataset.from_tensor_slices(tf.ones(1)))) \n",
    "\n",
    "        faces = faces.map(preprocess_twin)\n",
    "\n",
    "        faces = faces.take(1)\n",
    "        faces = faces.batch(1)\n",
    "\n",
    "        face_1, face_2, y_true = faces.as_numpy_iterator().next()\n",
    "\n",
    "        prediction = model.predict([face_1, face_2])\n",
    "        pred = np.round(prediction * 100,2)\n",
    "        \n",
    "        # Same person = green box around the faces and \"Verified\" + percentage on the screen\n",
    "        if prediction > 0.75:\n",
    "            for i, face_rect in enumerate(detected_faces):\n",
    "                cv2.rectangle(frame, (face_rect.left(), face_rect.top()),(face_rect.right(), face_rect.bottom()),(0,255,0),2)\n",
    "            cv2.putText(frame, f'Verified {pred}%', (200,40), cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,0),2) \n",
    "\n",
    "        # Different people = red box around the faces and \"Not Verified\" + percentage on the screen\n",
    "        else:\n",
    "            for i, face_rect in enumerate(detected_faces):\n",
    "                cv2.rectangle(frame, (face_rect.left(), face_rect.top()),(face_rect.right(), face_rect.bottom()),(0,0,255),2)\n",
    "            cv2.putText(frame, f'Not Verified {pred}%', (200,40), cv2.FONT_HERSHEY_COMPLEX,0.8,(0,0,255),2) \n",
    "   \n",
    "    # show image back to screen\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    # close the window\n",
    "    if cv2.waitKey(1) &  0XFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
